{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T00:40:40.680935Z",
     "start_time": "2018-06-13T00:40:38.924634Z"
    }
   },
   "outputs": [],
   "source": [
    "# snippet from ~/Library/Jupyter/nbextensions/snippets/snippets.json\n",
    "# basic\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import os, sys\n",
    "import dill\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "RANDOM_STATE = 777"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Pipeline and Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T00:40:40.792812Z",
     "start_time": "2018-06-13T00:40:40.725200Z"
    }
   },
   "outputs": [],
   "source": [
    "alnc_path = '/Users/nknezek/Documents/Insight_local/project/data/ALNC/Cleaned/NewspaperMapCorpus_03_03_2014_cleaned/'\n",
    "\n",
    "stop_stems = dill.load(open(\"/Users/nknezek/Documents/Insight_local/project/data/wordlists/stop_words/stop_stems.m\",'rb'))\n",
    "vocab_stems = dill.load(open(\"/Users/nknezek/Documents/Insight_local/project/data/wordlists/SCOWL-custom/vocab_stems.m\",'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make TF-IDF vectorizer with tokenizer and stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T00:40:41.072797Z",
     "start_time": "2018-06-13T00:40:41.059766Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'[a-zA-Z]+')\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "    stems = [stemmer.stem(x) for x in tokens]\n",
    "    return stems\n",
    "\n",
    "# vectorize the articles and compute count matrix\n",
    "tfidf_vectorizer = TfidfVectorizer(vocabulary=list(vocab_stems), stop_words=stop_stems, tokenizer=tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit to sampling of articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get filenames of articles and states and towns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T00:40:42.086134Z",
     "start_time": "2018-06-13T00:40:42.076322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 states found\n"
     ]
    }
   ],
   "source": [
    "states = os.listdir(alnc_path)\n",
    "print('{} states found'.format(len(states)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T00:40:42.594240Z",
     "start_time": "2018-06-13T00:40:42.484341Z"
    }
   },
   "outputs": [],
   "source": [
    "towns = {}\n",
    "town_counts = []\n",
    "for st in states:\n",
    "    towns[st] = os.listdir(alnc_path+st+'/')\n",
    "    town_counts.append(len(towns[st]))\n",
    "#     print('{} towns in {}'.format(len(towns[st]),st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T00:40:43.026544Z",
     "start_time": "2018-06-13T00:40:42.967795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/nknezek/Documents/Insight_local/project/data/ALNC/Cleaned/NewspaperMapCorpus_03_03_2014_cleaned/AK/Anchorage/www.thebristolbaytimes.com/2014-1-28-article38.cleaned',\n",
       " '/Users/nknezek/Documents/Insight_local/project/data/ALNC/Cleaned/NewspaperMapCorpus_03_03_2014_cleaned/AK/Anchorage/www.thebristolbaytimes.com/2014-1-28-article28.cleaned',\n",
       " '/Users/nknezek/Documents/Insight_local/project/data/ALNC/Cleaned/NewspaperMapCorpus_03_03_2014_cleaned/AK/Anchorage/www.thebristolbaytimes.com/2013-9-21-article1.cleaned',\n",
       " '/Users/nknezek/Documents/Insight_local/project/data/ALNC/Cleaned/NewspaperMapCorpus_03_03_2014_cleaned/AK/Anchorage/www.thebristolbaytimes.com/2014-1-21-article60.cleaned']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = 'AK/'\n",
    "town = 'Anchorage/'\n",
    "statetown = state + town\n",
    "\n",
    "def get_filenames_for_town(alnc_path, statetown, verbose=False):\n",
    "    papers = os.listdir(alnc_path + statetown)\n",
    "    files_list = []\n",
    "    for p in papers:\n",
    "        files_p = os.listdir(alnc_path + statetown + p)\n",
    "        files_list += [alnc_path + statetown + p + '/' + x for x in files_p]\n",
    "    if verbose:\n",
    "        print('{} files found for {}'.format(len(files_list), statetown))\n",
    "    return files_list\n",
    "\n",
    "file_list = get_filenames_for_town(alnc_path, statetown)\n",
    "file_list[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T00:40:43.514044Z",
     "start_time": "2018-06-13T00:40:43.508463Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_one_file(file):\n",
    "    with open(file,'r') as f:\n",
    "        raw_text = f.read()\n",
    "    return raw_text\n",
    "\n",
    "def make_corpus(file_list):\n",
    "    for file in file_list:\n",
    "        yield load_one_file(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the TF-IDF fit on 3 cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T00:40:44.314208Z",
     "start_time": "2018-06-13T00:40:44.308577Z"
    }
   },
   "outputs": [],
   "source": [
    "states2fit = ['AK/','CA/','TX/']\n",
    "towns2fit = {}\n",
    "towns2fit['AK/'] = ['Anchorage']\n",
    "towns2fit['CA/'] = ['Berkeley']\n",
    "towns2fit['TX/'] = ['Denton']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T16:33:58.627672Z",
     "start_time": "2018-06-13T16:33:57.940522Z"
    }
   },
   "outputs": [],
   "source": [
    "files_to_fit = []\n",
    "for st in states2fit:\n",
    "    for tn in towns2fit[st]:\n",
    "        statetown = st +tn+'/'\n",
    "        file_list = get_filenames_for_town(alnc_path, statetown)\n",
    "        for f in file_list:\n",
    "            files_to_fit.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T16:43:30.380007Z",
     "start_time": "2018-06-13T16:33:59.356898Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = make_corpus(files_to_fit)\n",
    "tfidf_vectorizer = tfidf_vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T16:43:33.220317Z",
     "start_time": "2018-06-13T16:43:31.082672Z"
    }
   },
   "outputs": [],
   "source": [
    "dill.dump(tfidf_vectorizer,open('tfidf_vectorizer.m','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test to make sure it transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T00:40:14.906047Z",
     "start_time": "2018-06-13T00:37:37.439Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = make_corpus(files_to_fit)\n",
    "tfidf_matrix = tfidf_func.transform(corpus)\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
