{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T16:06:54.491804Z",
     "start_time": "2018-06-22T16:06:53.179082Z"
    }
   },
   "outputs": [],
   "source": [
    "# snippet from ~/Library/Jupyter/nbextensions/snippets/snippets.json\n",
    "# basic\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import os, sys\n",
    "import dill\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "# re_tokenizer = RegexpTokenizer(r'\\w+')\n",
    "re_tokenizer = RegexpTokenizer(r'[a-zA-Z]+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T16:06:54.520575Z",
     "start_time": "2018-06-22T16:06:54.512675Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Months to stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T16:06:58.474007Z",
     "start_time": "2018-06-22T16:06:58.453353Z"
    }
   },
   "outputs": [],
   "source": [
    "month_names = [\n",
    "    'january',\n",
    "    'february',\n",
    "    'march',\n",
    "    'april',\n",
    "    'may',\n",
    "    'june',\n",
    "    'july',\n",
    "    'august',\n",
    "    'september',\n",
    "    'october',\n",
    "    'november',\n",
    "    'december',\n",
    "]\n",
    "month_abbrv = [\n",
    "    'jan',\n",
    "    'feb',\n",
    "    'mar',\n",
    "    'apr',\n",
    "    'may',\n",
    "    'jun',\n",
    "    'jul',\n",
    "    'aug',\n",
    "    'sep',\n",
    "    'oct',\n",
    "    'nov',\n",
    "    'dec',\n",
    "    'sept',\n",
    "]\n",
    "day_names = [\n",
    "    'sunday',\n",
    "    'monday',\n",
    "    'tuesday',\n",
    "    'wednesday',\n",
    "    'thursday',\n",
    "    'friday',\n",
    "    'saturday',\n",
    "    'sunday',\n",
    "]\n",
    "day_abbrv = [\n",
    "    'sun',\n",
    "    'mon',\n",
    "    'tue',\n",
    "    'wed',\n",
    "    'thu',\n",
    "    'fri',\n",
    "    'sat',\n",
    "    'sun',\n",
    "    'tues',\n",
    "    'weds',\n",
    "    'th',\n",
    "    'fr',\n",
    "]\n",
    "\n",
    "stop_words = stop_words.union(month_names)\n",
    "stop_words = stop_words.union(month_abbrv)\n",
    "stop_words = stop_words.union(day_names)\n",
    "stop_words = stop_words.union(day_abbrv)\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'[a-zA-Z]+')\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T16:06:58.519050Z",
     "start_time": "2018-06-22T16:06:58.503800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add city names to stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T16:06:58.673405Z",
     "start_time": "2018-06-22T16:06:58.549790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 states found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1948"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alnc_path = '/Users/nknezek/Documents/Insight_local/project/data/ALNC/Cleaned/NewspaperMapCorpus_03_03_2014_cleaned/'\n",
    "\n",
    "states = os.listdir(alnc_path)\n",
    "print('{} states found'.format(len(states)))\n",
    "\n",
    "for st in states:\n",
    "    stop_words.add(st)\n",
    "    towns = os.listdir(alnc_path + st + '/')\n",
    "    for town in towns:\n",
    "        stop_words.add(town.replace('_', ' '))\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add states and demonyms to stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T16:06:59.320638Z",
     "start_time": "2018-06-22T16:06:59.290025Z"
    }
   },
   "outputs": [],
   "source": [
    "states = [\n",
    "    'Alabama',\n",
    "    'Alaska',\n",
    "    'Arizona',\n",
    "    'Arkansas',\n",
    "    'California',\n",
    "    'Colorado',\n",
    "    'Connecticut',\n",
    "    'Delaware',\n",
    "    'Florida',\n",
    "    'Georgia',\n",
    "    'Hawaii',\n",
    "    'Idaho',\n",
    "    'Illinoi',\n",
    "    'Indiana',\n",
    "    'Iowa',\n",
    "    'Kansas',\n",
    "    'Kentucky',\n",
    "    'Louisiana',\n",
    "    'Maine',\n",
    "    'Maryland',\n",
    "    'Massachusetts',\n",
    "    'Michigan',\n",
    "    'Minnesota',\n",
    "    'Mississippi',\n",
    "    'Missouri',\n",
    "    'Montana',\n",
    "    'Nebraska',\n",
    "    'Nevada',\n",
    "    'New Hampshire',\n",
    "    'New Jersey',\n",
    "    'New Mexico',\n",
    "    'New York',\n",
    "    'North Carolina',\n",
    "    'North Dakota',\n",
    "    'Ohio',\n",
    "    'Oklahoma',\n",
    "    'Oregon',\n",
    "    'Pennsylvania',\n",
    "    'Rhode Island',\n",
    "    'South Carolina',\n",
    "    'South Dakota',\n",
    "    'Tennessee',\n",
    "    'Texas',\n",
    "    'Utah',\n",
    "    'Vermont',\n",
    "    'Virginia',\n",
    "    'Washington',\n",
    "    'West Virginia',\n",
    "    'Wisconsin',\n",
    "    'Wyoming',\n",
    "]\n",
    "stop_words = stop_words.union(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T16:06:59.810481Z",
     "start_time": "2018-06-22T16:06:59.759658Z"
    }
   },
   "outputs": [],
   "source": [
    "demonyms = [\n",
    "    'Alabamans ',\n",
    "    'Alabamians',\n",
    "    'Alaskans',\n",
    "    'Arizonans',\n",
    "    'Arkansans',\n",
    "    'Californians',\n",
    "    'Coloradans',\n",
    "    'Coloradoans',\n",
    "    'Connecticuters',\n",
    "    'Nutmeggers',\n",
    "    'Delawareans',\n",
    "    'Floridians',\n",
    "    'Georgians',\n",
    "    'Hawaiian',\n",
    "    'Idahoans',\n",
    "    'Illinoisans',\n",
    "    'Illinoisians',\n",
    "    'Indianan',\n",
    "    'Hoosiers',\n",
    "    'Iowans',\n",
    "    'Kansans',\n",
    "    'Kentuckians',\n",
    "    'Louisianans',\n",
    "    'Louisianians',\n",
    "    'Mainers',\n",
    "    'Down Easters',\n",
    "    'Marylanders',\n",
    "    'Massachusettsan',\n",
    "    'Bay Staters',\n",
    "    'Michiganders',\n",
    "    'Michiganians',\n",
    "    'Minnesotans',\n",
    "    'Mississippians',\n",
    "    'Missourians',\n",
    "    'Montanans',\n",
    "    'Nebraskans',\n",
    "    'Nevadans',\n",
    "    'New Hampshirites',\n",
    "    'New Jerseyites',\n",
    "    'New Jerseyans',\n",
    "    'New Mexicans',\n",
    "    'New Yorkers',\n",
    "    'North Carolinians',\n",
    "    'Tarheels',\n",
    "    'North Dakotans',\n",
    "    'Ohioans',\n",
    "    'Oklahomans',\n",
    "    'Oklahomians',\n",
    "    'Sooners',\n",
    "    'Okies',\n",
    "    'Oregonians',\n",
    "    'Pennsylvanians',\n",
    "    'Rhode Islanders',\n",
    "    'South Carolinians',\n",
    "    'South Dakotans',\n",
    "    'Tennesseeans',\n",
    "    'Texans',\n",
    "    'Utahns',\n",
    "    'Utahans',\n",
    "    'Vermonters',\n",
    "    'Virginians',\n",
    "    'Washingtonians',\n",
    "    'West Virginians',\n",
    "    'Wisconsinites',\n",
    "    'Wyomingites',\n",
    "]\n",
    "stop_words = stop_words.union(demonyms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add journalism words to stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T16:07:00.566758Z",
     "start_time": "2018-06-22T16:07:00.554917Z"
    }
   },
   "outputs": [],
   "source": [
    "jwords = [\n",
    "    'print',\n",
    "    'writer',\n",
    "    'author',\n",
    "    'daily',\n",
    "    'times',\n",
    "    'record',\n",
    "    'chronicle',\n",
    "    'font',\n",
    "    'publish',\n",
    "    'story',\n",
    "    'planet',\n",
    "    'comment',\n",
    "    'blotter',\n",
    "    'via',\n",
    "    'photo',\n",
    "    'picture',\n",
    "    'donate',\n",
    "    'staff',\n",
    "    'reporter',\n",
    "    'www',\n",
    "    'com',\n",
    "    'pm',\n",
    "    'am',\n",
    "    'email',\n",
    "    'update',\n",
    "    'columnist',\n",
    "]\n",
    "stop_words = stop_words.union(jwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get extra words from csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T16:07:01.474762Z",
     "start_time": "2018-06-22T16:07:01.458030Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./words_to_filter.csv', header=None)\n",
    "\n",
    "stop_words = stop_words.union(set(df[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newspaper Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T16:07:06.330239Z",
     "start_time": "2018-06-22T16:07:06.322327Z"
    }
   },
   "outputs": [],
   "source": [
    "paper_names = dill.load(open('../../../20city/papername_stop_dict.m','rb'))\n",
    "\n",
    "for k,v in paper_names.items():\n",
    "    stop_words = stop_words.union(set(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert words to stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T16:07:30.798012Z",
     "start_time": "2018-06-22T16:07:30.671614Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2060"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_stems = set()\n",
    "for w in stop_words:\n",
    "    ts = tokenizer.tokenize(w.lower())\n",
    "    for t in ts:\n",
    "        stm = stemmer.stem(t)\n",
    "        if stm not in stop_stems:\n",
    "            stop_stems.add(stm)\n",
    "len(stop_stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T16:07:36.350343Z",
     "start_time": "2018-06-22T16:07:36.288857Z"
    }
   },
   "outputs": [],
   "source": [
    "dill.dump(stop_stems,open(\"/Users/nknezek/Documents/Insight_local/project/data/wordlists/stop_words/stop_stems.m\",'wb'))\n",
    "dill.dump(stop_words,open(\"/Users/nknezek/Documents/Insight_local/project/data/wordlists/stop_words/stop_words.m\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
